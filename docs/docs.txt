Directory structure:
└── /./
    ├── .python-version
    ├── main.py
    ├── .env.example
    ├── docs/
    ├── app/
    │   ├── cli/
    │   │   ├── __init__.py
    │   │   └── commands/
    │   │       ├── link.py
    │   │       ├── import_export.py
    │   │       └── user.py
    │   ├── core/
    │   │   ├── settings.py
    │   │   ├── database/
    │   │   │   ├── __init__.py
    │   │   │   ├── models.py
    │   │   │   ├── crud.py
    │   │   │   ├── schemas.py
    │   │   │   └── repositories.py
    │   │   ├── services/
    │   │   │   └── import_export/
    │   │   │       ├── exporter.py
    │   │   │       └── importer.py
    │   │   └── logger.py
    │   └── __init__.py
    └── pyproject.toml

================================================
File: /.python-version
================================================
3.13


================================================
File: /main.py
================================================
from app.cli import cli_app

if __name__ == "__main__":
    cli_app()


================================================
File: /.env.example
================================================
DATABASE_NAME=app.db
DEBUG=False


================================================
File: /app/cli/__init__.py
================================================
from typer import Typer

from app.cli.commands import user, link  # , import_export
from app.core.settings import settings


# Initialize Typer for potential future CLI enhancements
cli_app = Typer(
    name=settings.APP_NAME,
    no_args_is_help=True,
    help=f"{settings.APP_NAME}, Bookmark management CLI Application",
)

cli_app.add_typer(user.app, name="user")
cli_app.add_typer(link.app, name="link")
# cli_app.add_typer(import_export.app, name="import-export")


================================================
File: /app/cli/commands/link.py
================================================
from typer import Typer, Option, Exit, prompt
from datetime import datetime, UTC

from app.core.logger import AppLogger
from app.core.database import user_service, link_service, Link


logger = AppLogger(__name__)

app = Typer()


@app.command(help="Add a new link to the database.")
def create(
    url: str | None = Option(None, help="URL of the link."),
    domain: str | None = Option(None, help="Domain of the link."),
    author_email: str | None = Option(None, help="Email of the author."),
    description: str | None = Option("", help="Description of the link."),
    tags: list[str] = Option([], "--tag", "-t", help="Tags associated with the link."),
) -> None:
    """
    Add a new link to the database.
    """
    if not url:
        url = prompt("URL of the link")
    if not domain:
        domain = prompt("Domain of the link")
    if not author_email:
        author_email = prompt("Author's email")

    if not (user := user_service.get_user(user_email=author_email)):
        logger.error(f"Author with email '{author_email}' does not exist.")
        raise Exit(code=1)

    link = Link(
        url=url,
        description=description,
        domain=domain,
        tag=tags,
        author_id=user.id,
    )

    if link_id := link_service.create_link(link):
        logger.info(f"Link added with ID: {link_id}")
    else:
        logger.error("Failed to add link.")


@app.command(help="List all links with their authors.")
def list_link() -> None:
    """
    List all links with their authors.
    """
    if not (links := link_service.get_links()):
        logger.warning("No links found.")
        return None

    for entry in links:
        link: Link = entry["link"]
        logger.info(f"ID: {link.id}, URL: {link.url}, Domain: {link.domain}, Author: {link.author}")


@app.command(help="Search for links based on domain, tags, or description.")
def search(
    domain: str | None = Option(None, help="Filter by domain."),
    tags: list[str] = Option([], "--tag", "-t", help="Tags to filter by."),
    description: str | None = Option(None, help="Filter by description."),
    sort_by: str = Option("created_at", help="Field to sort by."),
    sort_order: str = Option("ASC", help="Sort order: ASC or DESC."),
    limit: int = Option(3, help="Number of results to return."),
    offset: int = Option(0, help="Number of results to skip."),
    is_read: bool | None = Option(None, help="Filter by read status."),
) -> None:
    """
    Search for links based on domain, tags, or description.
    """
    results = link_service.search_links(
        domain=domain,
        tags=tags,
        description=description,
        sort_by=sort_by,
        sort_order=sort_order,
        limit=limit,
        offset=offset,
        is_read=is_read,
    )
    if not results:
        logger.warning("No matching links found.")
        return None
    for link in results:
        logger.info(
            f"ID: {link.id}, URL: {link.url}, Domain: {link.domain}, Description: {link.description}, Tags: {', '.join(link.tag)}"
        )


@app.command(help="Delete a link by its ID.")
def delete(link_id: int = Option(..., help="ID of the link to delete.")) -> None:
    """
    Delete a link by its ID.
    """
    if link_service.delete_link(link_id):
        logger.info(f"Link with ID {link_id} has been deleted.")
    else:
        logger.error(f"Failed to delete link with ID {link_id}.")


@app.command(help="Update a link's details by its ID.")
def update(
    link_id: int = Option(..., help="ID of the link to update."),
    url: str | None = Option(None, help="New URL of the link."),
    domain: str | None = Option(None, help="New domain of the link."),
    description: str | None = Option(None, help="New description of the link."),
    tags: list[str] | None = Option(None, "--tag", "-t", help="New tags for the link."),
    is_read: bool | None = Option(None, help="Mark as read or unread."),
) -> None:
    """
    Update a link's details by its ID.
    """

    if not (existing_link := link_service.get_link(link_id)):
        logger.error(f"No link found with ID {link_id}.")
        raise Exit(code=1)

    if url is None and domain is None and description is None and tags is None and is_read is None:
        logger.warning("No updates provided. Use options to specify fields to update.")
        raise Exit()

    if url:
        existing_link.url = url
    if domain:
        existing_link.domain = domain
    if description is not None:
        existing_link.description = description
    if tags is not None:
        existing_link.tag = tags
    if is_read is not None:
        existing_link.is_read = is_read

    existing_link.updated_at = datetime.now(UTC).isoformat()

    if link_service.update_link(link_id, existing_link):
        logger.info(f"Link with ID {link_id} has been updated.")
    else:
        logger.error(f"Failed to update link with ID {link_id}.")


@app.command("read-link", help="Mark 3 links as read.")
def mark_links_as_read(auther_id: str | None = Option(None)) -> None:
    """
    Retrieve 3 links from the database and mark them as read (is_read = 1).
    """
    if not (links := link_service.get_links_by_author(author_id=auther_id, number=3)):
        logger.warning("No links found to update.")
        return

    link_ids = [link.id for link in links if link.id is not None]
    link_service.update_is_read_for_links(link_ids)

    for link in links:
        logger.info(f"Marked link {link.id} as read: {link.url}")


================================================
File: /app/cli/commands/import_export.py
================================================
from typer import Typer, Option, Exit, prompt
from os import path
from pathlib import Path
from json import load

from app.core.logger import AppLogger
from app.core.models_old import db
from app.core.services.import_export.importer import (
    check_file,
    import_txt,
    import_csv,
    import_links_from_json,
)
from app.core.services.import_export.exporter import (
    export_users_to_json,
    export_users_to_csv,
    export_links_to_json,
    export_links_to_csv,
    export_all,
)


logger = AppLogger(__name__)

app = Typer()


@app.command("import", help="Import links from a TXT or CSV file.")
def import_links(
    file_path: str = Option(..., help="Path to the .txt or .csv file to import."),
    author_id: int = Option(..., help="ID of the author to associate with the imported links."),
) -> None:
    """
    Import links from a TXT or CSV file into the database.
    """
    try:
        if check_file(file_path):
            extension = path.splitext(file_path)[1].lower()
            try:
                if extension == ".txt":
                    import_txt(file_path, author_id, db)
                elif extension == ".csv":
                    import_csv(file_path, author_id, db)
                elif extension == ".json":
                    with open(file_path, "r", encoding="utf-8") as json_file:
                        data = load(json_file)
                        if isinstance(data, list) and all("url" in item for item in data):
                            import_links_from_json(file_path, db)
                else:
                    logger.error(f"Unsupported file extension: {extension}")
            except Exception as e:
                logger.error(f"Import failed: {e}")
    except FileNotFoundError as fnf_error:
        logger.error(f"{fnf_error}")
        raise Exit(code=1)
    except ValueError as val_error:
        logger.error(f"{val_error}")
        raise Exit(code=1)
    except Exception as e:
        logger.error(f"An unexpected error occurred: {e}")
        raise Exit(code=1)


@app.command("export-users", help="Export all users to a JSON or CSV file.")
def export_users(
    format: str = Option("json", "--format", "-f", help="Export format: json or csv", show_default=True),
    output: str = Option("users_export.json", "--output", "-o", help="Output file path", show_default=True),
) -> None:
    """
    Export all users to the specified format (JSON or CSV).
    """
    format = format.lower()
    if format == "json":
        export_users_to_json(db, output)
    elif format == "csv":
        export_users_to_csv(db, output)
    else:
        logger.error(f"Unsupported export format: {format}. Choose 'json' or 'csv'.")


@app.command("export-links", help="Export all links to a JSON or CSV file.")
def export_links(
    format: str = Option("json", "--format", "-f", help="Export format: json or csv", show_default=True),
    output: str = Option("links_export.json", "--output", "-o", help="Output file path", show_default=True),
) -> None:
    """
    Export all links to the specified format (JSON or CSV).
    """
    format = format.lower()
    if format == "json":
        export_links_to_json(db, output)
    elif format == "csv":
        export_links_to_csv(db, output)
    else:
        logger.error(f"Unsupported export format: {format}. Choose 'json' or 'csv'.")


@app.command("export-all", help="Export all users and links to JSON or CSV files.")
def export_all_command(
    format: str = Option(
        "json", "--format", "-f", help="Export format for both users and links: json or csv", show_default=True
    ),
    output_dir: str | None = Option(None, "--output-dir", "-d", help="Directory to store exported files."),
) -> None:
    """
    Export all users and links to the specified format (JSON or CSV) within a directory.
    """
    format = format.lower()
    if format not in {"json", "csv"}:
        logger.error(f"Unsupported export format: {format}. Choose 'json' or 'csv'.")
        raise Exit(code=1)

    if not output_dir:
        output_dir = Path.cwd()
    else:
        output_dir = Path(output_dir)
        try:
            output_dir.mkdir(parents=True, exist_ok=True)
        except Exception as e:
            logger.error(f"Failed to create directory '{output_dir}': {e}")
            raise Exit(code=1)

    users_output = output_dir / f"users_export.{format}"
    links_output = output_dir / f"links_export.{format}"

    for output_path in [users_output, links_output]:
        if output_path.exists():
            overwrite = prompt(f"File '{output_path}' already exists. Overwrite? (y/n)", default="n")
            if overwrite.lower() != "y":
                logger.warning(f"Skipped exporting to '{output_path}'.")
                raise Exit()

    export_all(db, format, str(output_dir))


================================================
File: /app/cli/commands/user.py
================================================
from typer import Typer, Option
from rich.table import Table

from app.core.logger import AppLogger
from app.core.database import user_service


logger = AppLogger(__name__)

app = Typer()


@app.command()
def list():
    """List all users"""
    table = Table(title="Users")
    table.add_column("ID", style="cyan")
    table.add_column("Name", style="magenta")
    table.add_column("Email", style="green")

    for user in user_service.get_users():
        table.add_row(str(user.id), user.name, user.email)

    logger.print(table)


@app.command()
def create(name: str = Option(..., prompt=True), email: str = Option(..., prompt=True)):
    """Create new user"""
    user = user_service.create_user({"name": name, "email": email})
    logger.print(f"User created with ID: {user.id}")


@app.command()
def delete(user_id: int):
    """Delete user"""
    user_service.delete_user(user_id)
    logger.print(f"User with ID: {user_id} deleted")


@app.command()
def update(user_id: int, name: str = Option(None, prompt=True), email: str = Option(None, prompt=True)):
    """Update user information"""
    update_data = {}
    if name:
        update_data["name"] = name
    if email:
        update_data["email"] = email

    _ = user_service.update_user(user_id, update_data)
    logger.print(f"User with ID: {user_id} updated successfully")


================================================
File: /app/core/settings.py
================================================
from rich import pretty, traceback
from pydantic_settings import BaseSettings


class Settings(BaseSettings):
    traceback.install(show_locals=True)
    pretty.install()

    APP_NAME: str = "LinkCovery"
    DATABASE_NAME: str = "app.db"
    DEBUG: bool = False
    ALLOW_EXTENSIONS: list = [
        "csv",
        "txt",
        "json",
    ]

    class Config:
        env_file = ".env"
        env_file_encoding = "utf-8"


settings = Settings()


================================================
File: /app/core/database/__init__.py
================================================
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

from app.core.settings import settings
from app.core.database.models import Base, User, Link
from app.core.database.crud import UserService, LinkService

engine = create_engine(f"sqlite:///{settings.DATABASE_NAME}")
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# Create tables
Base.metadata.create_all(bind=engine)

# Initialize services
session = SessionLocal()
user_service = UserService(session)
link_service = LinkService(session)

__all__ = ["user_service", "link_service", "User", "Link"]


================================================
File: /app/core/database/models.py
================================================
from sqlalchemy import Column, Integer, String, Boolean, ForeignKey
from sqlalchemy.orm import relationship, declarative_base, validates

Base = declarative_base()


class User(Base):
    __tablename__ = "users"

    id = Column(Integer, primary_key=True, autoincrement=True)
    name = Column(String, nullable=False)
    email = Column(String, nullable=False, unique=True)

    links = relationship("Link", back_populates="author")

    @validates("name")
    def validate_name(self, key, value):
        if len(value) < 4:
            raise ValueError("Name must be at least 4 characters long.")
        return value

    @validates("email")
    def validate_email(self, key, value):
        return value


class Link(Base):
    __tablename__ = "links"

    id = Column(Integer, primary_key=True, autoincrement=True)
    url = Column(String, nullable=False)
    domain = Column(String, nullable=False)
    description = Column(String, nullable=True)
    tag = Column(String, nullable=False)
    author_id = Column(Integer, ForeignKey("users.id"), nullable=False)
    is_read = Column(Boolean, default=False)
    created_at = Column(String, nullable=False)
    updated_at = Column(String, nullable=False)

    author = relationship("User", back_populates="links")

    @validates("url")
    def validate_url(self, key, value):
        if not value.startswith("http://") and not value.startswith("https://"):
            raise ValueError("Invalid URL format.")
        return value

    @validates("domain")
    def validate_domain(self, key, value):
        if not value or len(value.strip()) == 0:
            raise ValueError("Domain cannot be empty or just whitespace.")
        if "." not in value:
            raise ValueError("Domain must contain at least one dot.")
        return value.lower()

    @validates("author_id")
    def validate_author(self, key, value):
        if not value:
            raise ValueError("Author ID is required.")
        return value


================================================
File: /app/core/database/crud.py
================================================
from sqlalchemy.orm import Session

from app.core.database.repositories import UserRepository, LinkRepository


class UserService:
    def __init__(self, session: Session):
        self.user_repository = UserRepository(session)

    def create_user(self, user_data):
        return self.user_repository.create(user_data)

    def get_user(self, user_id: int | None = None, user_email: str | None = None):
        if user_id:
            return self.user_repository.get_by_id(user_id)
        elif user_email:
            return self.user_repository.get_by_email(user_email)
        else:
            return None

    def update_user(self, user_id: int, user_data):
        return self.user_repository.update(user_id, user_data)

    def delete_user(self, user_id: int):
        return self.user_repository.delete(user_id)

    def get_users(self):
        return self.user_repository.get_all()


class LinkService:
    def __init__(self, session: Session):
        self.link_repository = LinkRepository(session)

    def create_link(self, link_data):
        return self.link_repository.create(link_data)

    def get_link(self, link_id: int | None = None, link_url: str | None = None):
        if link_id:
            return self.link_repository.get_by_id(link_id)
        elif link_url:
            return self.link_repository.get_by_url(link_url)
        else:
            return None

    def search_links(self, search_criteria):
        return self.link_repository.search(search_criteria)

    def update_link(self, link_id: int, link_data):
        return self.link_repository.update(link_id, link_data)

    def delete_link(self, link_id: int):
        return self.link_repository.delete(link_id)

    def get_links(self):
        return self.link_repository.get_all()

    def get_links_by_author(self, author_id: int, number: int | None = None):
        return self.link_repository.get_links_by_author(author_id, number)


================================================
File: /app/core/database/schemas.py
================================================
from pydantic import BaseModel, EmailStr, HttpUrl


class UserCreate(BaseModel):
    name: str
    email: EmailStr

    class Config:
        orm_mode = True


class LinkCreate(BaseModel):
    url: HttpUrl
    description: str | None = None
    tag: list[str]
    created_at: str
    updated_at: str
    author_id: int

    class Config:
        orm_mode = True


class UserUpdate(BaseModel):
    name: str | None = None
    email: EmailStr | None = None

    class Config:
        orm_mode = True


class LinkUpdate(BaseModel):
    url: HttpUrl | None = None
    description: str | None = None
    tag: list[str] | None = None
    is_read: None | None = None

    class Config:
        orm_mode = True


================================================
File: /app/core/database/repositories.py
================================================
from sqlalchemy.orm import Session

from app.core.database.models import User, Link


class UserRepository:
    def __init__(self, session: Session):
        self.session = session

    def create(self, user_data):
        user = User(**user_data)
        self.session.add(user)
        self.session.commit()
        return user

    def get_by_id(self, user_id: int):
        return self.session.query(User).filter(User.id == user_id).first()

    def get_by_email(self, email: str):
        return self.session.query(User).filter(User.email == email).first()

    def update(self, user_id: int, user_data):
        if user := self.get_by_id(user_id):
            for key, value in user_data.items():
                setattr(user, key, value)
            self.session.commit()
        return user

    def delete(self, user_id: int):
        if user := self.get_by_id(user_id):
            self.session.delete(user)
            self.session.commit()

    def get_all(self):
        return self.session.query(User).all()


class LinkRepository:
    def __init__(self, session: Session):
        self.session = session

    def create(self, link_data):
        link = Link(**link_data)
        self.session.add(link)
        self.session.commit()
        return link

    def get_by_id(self, link_id: int):
        return self.session.query(Link).filter(Link.id == link_id).first()

    def get_by_url(self, url: str):
        return self.session.query(Link).filter(Link.url == url).first()

    def search(self, search_criteria):
        query = self.session.query(Link)
        if "url" in search_criteria:
            query = query.filter(Link.url.contains(search_criteria["url"]))
        if "tag" in search_criteria:
            query = query.filter(Link.tag.contains(search_criteria["tag"]))
        return query.all()

    def update(self, link_id: int, link_data):
        if link := self.get_by_id(link_id):
            for key, value in link_data.items():
                setattr(link, key, value)
            self.session.commit()
        return link

    def delete(self, link_id: int):
        if link := self.get_by_id(link_id):
            self.session.delete(link)
            self.session.commit()

    def get_all(self):
        return self.session.query(Link).all()

    def get_links_by_author(self, author_id: int, number: int | None = None):
        if number:
            return self.session.query(Link).filter(Link.author_id == author_id).limit(number).all()
        return self.session.query(Link).filter(Link.author_id == author_id).all()


================================================
File: /app/core/services/import_export/exporter.py
================================================
from csv import DictWriter
from json import dump
from rich.progress import track
from pathlib import Path

from app.core.models_old import LinkDatabase, User, Link
from app.core.logger import AppLogger

logger = AppLogger(__name__)


def export_users_to_json(db: LinkDatabase, output_path: str) -> None:
    """
    Exports all users to a JSON file.

    Args:
        db (LinkDatabase): The database instance.
        output_path (str): Path to the output JSON file.
    """
    users: list[User] = db.read_users()
    users_data = [user.model_dump() for user in users]

    try:
        with open(output_path, "w", encoding="utf-8") as json_file:
            dump(users_data, json_file, indent=4)
        logger.info(f"Successfully exported {len(users)} users to {output_path}.")
    except Exception as e:
        logger.error(f"Failed to export users to JSON: {e}")


def export_users_to_csv(db: LinkDatabase, output_path: str) -> None:
    """
    Exports all users to a CSV file.

    Args:
        db (LinkDatabase): The database instance.
        output_path (str): Path to the output CSV file.
    """
    users: list[User] = db.read_users()
    if not users:
        logger.warning("No users available to export.")
        return

    try:
        with open(output_path, "w", newline="", encoding="utf-8") as csv_file:
            writer = DictWriter(csv_file, fieldnames=users[0].model_dump().keys())
            writer.writeheader()
            for user in track(users, description="Exporting users..."):
                writer.writerow(user.dict())
        logger.info(f"Successfully exported {len(users)} users to {output_path}.")
    except Exception as e:
        logger.error(f"Failed to export users to CSV: {e}")


def export_links_to_json(db: LinkDatabase, output_path: str) -> None:
    """
    Exports all links to a JSON file.

    Args:
        db (LinkDatabase): The database instance.
        output_path (str): Path to the output JSON file.
    """
    links_with_authors = db.read_links_with_authors()
    links_data = []
    for entry in links_with_authors:
        link = entry["link"].dict()
        link["author"] = entry["author"]
        links_data.append(link)

    try:
        with open(output_path, "w", encoding="utf-8") as json_file:
            dump(links_data, json_file, indent=4)
        logger.info(f"Successfully exported {len(links_data)} links to {output_path}.")
    except Exception as e:
        logger.error(f"Failed to export links to JSON: {e}")


def export_links_to_csv(db: LinkDatabase, output_path: str) -> None:
    """
    Exports all links to a CSV file.

    Args:
        db (LinkDatabase): The database instance.
        output_path (str): Path to the output CSV file.
    """
    links_with_authors = db.read_links_with_authors()
    if not links_with_authors:
        logger.warning("No links available to export.")
        return

    headers = [
        "id",
        "url",
        "domain",
        "description",
        "tag",
        "author_id",
        "is_read",
        "created_at",
        "updated_at",
        "author_name",
        "author_email",
    ]

    try:
        with open(output_path, "w", newline="", encoding="utf-8") as csv_file:
            writer = DictWriter(csv_file, fieldnames=headers)
            writer.writeheader()
            for entry in track(links_with_authors, description="Exporting links..."):
                link: Link = entry["link"]
                author = entry["author"]
                row = link.model_dump()
                row["tag"] = ", ".join(link.tag)
                row["author_name"] = author["name"]
                row["author_email"] = author["email"]
                writer.writerow(row)
        logger.info(f"Successfully exported {len(links_with_authors)} links to {output_path}.")
    except Exception as e:
        logger.error(f"Failed to export links to CSV: {e}")


def export_all(db: LinkDatabase, format: str = "json", output_dir: str | None = None) -> None:
    """
    Exports both users and links to the specified format.

    Args:
        db (LinkDatabase): The database instance.
        format (str): Export format ('json' or 'csv').
        output_dir (Optional[str]): Directory to store exported files. Defaults to current directory.
    """
    format = format.lower()
    if format not in {"json", "csv"}:
        logger.error(f"Unsupported export format: {format}. Choose 'json' or 'csv'.")
        return

    if not output_dir:
        output_dir = Path.cwd()
    else:
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)

    users_output = output_dir / f"users_export.{format}"
    links_output = output_dir / f"links_export.{format}"

    if format == "json":
        export_users_to_json(db, str(users_output))
        export_links_to_json(db, str(links_output))
    elif format == "csv":
        export_users_to_csv(db, str(users_output))
        export_links_to_csv(db, str(links_output))

    logger.info(f"Exported all data successfully to '{users_output}' and '{links_output}'.")


================================================
File: /app/core/services/import_export/importer.py
================================================
from os import path
from rich import print
from pydantic import HttpUrl, ValidationError
from urllib.parse import urlparse
from csv import DictReader
from json import JSONDecodeError, load

from app.core.models_old import LinkDatabase, User, Link
from app.core.settings import settings


def check_file(file_path: str) -> bool:
    """
    Validates the existence and extension of the provided file.

    Args:
        file_path (str): Path to the file to be checked.

    Returns:
        bool: True if the file exists and has a valid extension.

    Raises:
        FileNotFoundError: If the file does not exist.
        ValueError: If the file extension is not allowed.
    """
    if not path.exists(file_path):
        raise FileNotFoundError(f"File not found: {file_path}")

    extension = path.splitext(file_path)[1].lower()
    if extension not in {f".{ext}" for ext in settings.ALLOW_EXTENSIONS}:
        raise ValueError(f"Invalid file extension: {extension}. Allowed extensions: {settings.ALLOW_EXTENSIONS}")

    return True


def extract_domain(url: str) -> str:
    """
    Extracts the domain from a given URL.

    Args:
        url (str): The URL from which to extract the domain.

    Returns:
        str: The domain of the URL.
    """
    parsed_url = urlparse(url)
    return parsed_url.netloc


def parse_tags(domain: str) -> list[str]:
    """
    Generates tags based on the domain.

    Args:
        domain (str): The domain to generate tags from.

    Returns:
        List[str]: A list of tags.
    """
    return domain.split(".")


def import_txt(file_path: str, author_id: int, db: LinkDatabase):
    """
    Imports links from a .txt file. Each line in the file should contain one URL.

    Args:
        file_path (str): Path to the .txt file.
        author_id (int): ID of the author to associate with the imported links.
        db (LinkDatabase): Instance of the database connection.
    """
    try:
        with open(file_path, "r", encoding="utf-8") as txtfile:
            links = [line.strip() for line in txtfile if line.strip()]

        if not links:
            print("[yellow]No links found in the TXT file.[/yellow]")
            return

        with db.transaction():
            for line_number, link in enumerate(links, start=1):
                try:
                    url = HttpUrl(link)
                    domain = extract_domain(str(url))
                    tags = parse_tags(domain)
                    link_obj = Link(
                        id=None,
                        url=url,
                        domain=domain,
                        description="Imported from TXT",
                        tag=tags,
                        author_id=author_id,
                    )
                    link_id = db.create_link(link_obj)
                    if link_id:
                        print(f"[green]Line {line_number}: Link imported with ID {link_id}.[/green]")
                except ValidationError as ve:
                    print(f"[red]Line {line_number}: Invalid URL '{link}'. Error: {ve}[/red]")
                    raise  # Trigger transaction rollback
                except Exception as e:
                    print(f"[red]Line {line_number}: Failed to import link '{link}'. Error: {e}[/red]")
                    raise  # Trigger transaction rollback

        print("[green]All links from TXT file have been imported successfully.[/green]")
    except Exception as e:
        print(f"[red]Failed to import from TXT file: {e}[/red]")


def import_csv(file_path: str, author_id: int, db: LinkDatabase):
    """
    Imports links from a .csv file. The CSV should have headers corresponding to Link fields.

    Expected CSV Headers:
    - url
    - domain
    - description
    - tag (comma-separated if multiple)
    - is_read

    Args:
        file_path (str): Path to the .csv file.
        author_id (int): ID of the author to associate with the imported links.
        db (LinkDatabase): Instance of the database connection.
    """
    try:
        with open(file_path, "r", encoding="utf-8") as csvfile:
            reader = DictReader(csvfile)
            required_fields = {"url", "domain", "description", "tag", "is_read"}
            if not required_fields.issubset(reader.fieldnames):
                print(f"[red]CSV file is missing required fields. Required fields: {required_fields}[/red]")
                return

            links = list(reader)
            if not links:
                print("[yellow]No links found in the CSV file.[/yellow]")
                return

            with db.transaction():
                for row_number, row in enumerate(links, start=2):  # Start at 2 considering header
                    try:
                        url = HttpUrl(row["url"])
                        domain = row["domain"] or extract_domain(str(url))
                        tags = [tag.strip() for tag in row["tag"].split(",")] if row["tag"] else []
                        is_read = row.get("is_read", "False").strip().lower() in {"1", "true", "yes"}

                        link_obj = Link(
                            id=None,
                            url=url,
                            domain=domain,
                            description=row.get("description", "Imported from CSV"),
                            tag=tags,
                            author_id=author_id,
                            is_read=is_read,
                        )
                        link_id = db.create_link(link_obj)
                        if link_id:
                            print(f"[green]Row {row_number}: Link imported with ID {link_id}.[/green]")
                    except ValidationError as ve:
                        print(f"[red]Row {row_number}: Invalid data. Error: {ve}[/red]")
                        raise  # Trigger transaction rollback
                    except Exception as e:
                        print(f"[red]Row {row_number}: Failed to import link. Error: {e}[/red]")
                        raise  # Trigger transaction rollback

        print("[green]All links from CSV file have been imported successfully.[/green]")
    except Exception as e:
        print(f"[red]Failed to import from CSV file: {e}[/red]")


def import_links_from_json(file_path: str, db: LinkDatabase):
    """
    Imports links from a JSON file.

    Args:
        file_path (str): Path to the JSON file.
        db (LinkDatabase): Instance of the database connection.
    """
    try:
        with open(file_path, "r", encoding="utf-8") as json_file:
            links_data = load(json_file)

        if not links_data:
            print("[yellow]No links found in the JSON file.[/yellow]")
            return

        new_links = []
        for index, link_dict in enumerate(links_data, start=1):
            try:
                # Extract author_email to find or create the user
                author_info = link_dict.pop("author", {})
                author_email = author_info.get("email")
                if not author_email:
                    print(f"[red]Link {index}: Missing author email. Skipping.[/red]")
                    continue

                user = db.get_user_by_email(author_email)
                if not user:
                    # Optionally, create the user if they don't exist
                    user = User(name=author_info.get("name", "Unknown"), email=author_email)
                    user_id = db.create_user(user)
                    if not user_id:
                        print(f"[red]Link {index}: Failed to create user '{author_email}'. Skipping link.[/red]")
                        continue
                    user.id = user_id

                # Prepare Link object
                link_obj = Link(**link_dict)
                link_obj.author_id = user.id

                # Check if link already exists
                existing_link = db.read_link_by_url(link_obj.url)
                if existing_link:
                    print(f"[yellow]Link with URL '{link_obj.url}' already exists. Skipping.[/yellow]")
                    continue

                new_links.append(link_obj)
            except ValidationError as ve:
                print(f"[red]Link {index}: Validation error: {ve}[/red]")
                raise  # Trigger transaction rollback
            except Exception as e:
                print(f"[red]Link {index}: Failed to prepare link. Error: {e}[/red]")
                raise  # Trigger transaction rollback

        if new_links:
            db.bulk_create_links(new_links)
            print(f"[green]Successfully imported {len(new_links)} links from JSON file.[/green]")
        else:
            print("[yellow]No new links to import.[/yellow]")

    except JSONDecodeError as jde:
        print(f"[red]Invalid JSON format: {jde}[/red]")
    except Exception as e:
        print(f"[red]Failed to import links from JSON file: {e}[/red]")


================================================
File: /app/core/logger.py
================================================
from logging import getLogger, Formatter, DEBUG, INFO
from rich.console import Console
from rich.logging import RichHandler

from .settings import settings


class AppLogger:
    def __init__(self, name: str):
        self.console = Console()
        self.logger = getLogger(name)
        self.logger.setLevel(DEBUG if settings.DEBUG else INFO)
        log_handler = RichHandler(
            show_time=settings.DEBUG,
            show_level=settings.DEBUG,
            show_path=settings.DEBUG,
            rich_tracebacks=True,
            console=self.console,
        )
        log_handler.setLevel(DEBUG if settings.DEBUG else INFO)

        if settings.DEBUG:
            formatter = Formatter("[%(asctime)s] %(name)s - %(levelname)s: %(message)s")
        else:
            formatter = Formatter("%(message)s")
        log_handler.setFormatter(formatter)

        self.logger.addHandler(log_handler)

    def debug(self, msg: str) -> None:
        self.logger.debug(msg)

    def info(self, msg: str) -> None:
        self.logger.info(msg)

    def warning(self, msg: str) -> None:
        self.logger.warning(msg)

    def error(self, msg: str) -> None:
        self.logger.error(msg)

    def critical(self, msg: str) -> None:
        self.logger.critical(msg)

    def exception(self, msg: str) -> None:
        self.logger.exception(msg)

    def print(self, msg: str) -> None:
        self.console.print(msg)


================================================
File: /pyproject.toml
================================================
[project]
name = "linkcovery"
version = "0.3.0"
description = "Bookmark and Link discovery tool for people with love and Python :)"
readme = "README.md"
authors = [{name = "Arian Omrani"}]
requires-python = ">=3.13"
dependencies = [
    "pydantic[email]>=2.10.6",
    "pydantic-settings>=2.7.1",
    "rich>=13.9.4",
    "sqlalchemy>=2.0.38",
    "typer>=0.15.1",
]

[dependency-groups]
dev = [
    "alembic>=1.14.1",
    "pytest>=8.3.4",
    "sqlite-web>=0.6.4",
]

[tool.ruff]
line-length = 120

[project.urls]
Homepage = "https://github.com/arian24b/linkcovery"
Issues = "https://github.com/arian24b/linkcovery/issues"

[project.scripts]
linkcovery = "main:cli_app"

[tool.uv]
package = true
